{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (389163, 15)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98528.0</td>\n",
       "      <td>2017-07-04 16:42</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589714.0</td>\n",
       "      <td>2017-07-07 07:40</td>\n",
       "      <td>1035283.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478652.0</td>\n",
       "      <td>2017-07-07 20:42</td>\n",
       "      <td>65994.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34536.0</td>\n",
       "      <td>2017-07-05 15:05</td>\n",
       "      <td>75976.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71863.0</td>\n",
       "      <td>2017-07-06 20:11</td>\n",
       "      <td>987498.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id          DateTime    user_id product  campaign_id  webpage_id  \\\n",
       "0     98528.0  2017-07-04 16:42     7716.0       C     405490.0     60305.0   \n",
       "1    589714.0  2017-07-07 07:40  1035283.0       I     118601.0     28529.0   \n",
       "2    478652.0  2017-07-07 20:42    65994.0       H     359520.0     13787.0   \n",
       "3     34536.0  2017-07-05 15:05    75976.0       H     405490.0     60305.0   \n",
       "4     71863.0  2017-07-06 20:11   987498.0       C     405490.0     60305.0   \n",
       "\n",
       "   product_category_1  product_category_2  user_group_id  gender  age_level  \\\n",
       "0                 3.0                 NaN            3.0    Male        3.0   \n",
       "1                 4.0             82527.0           10.0  Female        4.0   \n",
       "2                 4.0                 NaN            4.0    Male        4.0   \n",
       "3                 3.0                 NaN            3.0    Male        3.0   \n",
       "4                 3.0                 NaN            2.0    Male        2.0   \n",
       "\n",
       "   user_depth  city_development_index  var_1  is_click  \n",
       "0         3.0                     NaN    1.0       1.0  \n",
       "1         3.0                     3.0    1.0       0.0  \n",
       "2         3.0                     2.0    0.0       0.0  \n",
       "3         3.0                     3.0    0.0       0.0  \n",
       "4         3.0                     2.0    0.0       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 389163 entries, 0 to 389162\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   session_id              384997 non-null  float64\n",
      " 1   DateTime                385054 non-null  object \n",
      " 2   user_id                 385055 non-null  float64\n",
      " 3   product                 384989 non-null  object \n",
      " 4   campaign_id             384975 non-null  float64\n",
      " 5   webpage_id              385006 non-null  float64\n",
      " 6   product_category_1      384962 non-null  float64\n",
      " 7   product_category_2      80928 non-null   float64\n",
      " 8   user_group_id           369844 non-null  float64\n",
      " 9   gender                  369839 non-null  object \n",
      " 10  age_level               369854 non-null  float64\n",
      " 11  user_depth              369841 non-null  float64\n",
      " 12  city_development_index  281026 non-null  float64\n",
      " 13  var_1                   385002 non-null  float64\n",
      " 14  is_click                385031 non-null  float64\n",
      "dtypes: float64(12), object(3)\n",
      "memory usage: 44.5+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the training dataset\n",
    "ctr_df = pd.read_csv('../data/train_dataset_full.csv')\n",
    "\n",
    "# Display first few rows and basic info\n",
    "print(\"Dataset shape:\", ctr_df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(ctr_df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "ctr_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98528.0</td>\n",
       "      <td>2017-07-04 16:42</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589714.0</td>\n",
       "      <td>2017-07-07 07:40</td>\n",
       "      <td>1035283.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478652.0</td>\n",
       "      <td>2017-07-07 20:42</td>\n",
       "      <td>65994.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34536.0</td>\n",
       "      <td>2017-07-05 15:05</td>\n",
       "      <td>75976.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71863.0</td>\n",
       "      <td>2017-07-06 20:11</td>\n",
       "      <td>987498.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389158</th>\n",
       "      <td>464382.0</td>\n",
       "      <td>2017-07-02 08:03</td>\n",
       "      <td>927351.0</td>\n",
       "      <td>I</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389159</th>\n",
       "      <td>446419.0</td>\n",
       "      <td>2017-07-04 21:14</td>\n",
       "      <td>698480.0</td>\n",
       "      <td>H</td>\n",
       "      <td>360936.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389160</th>\n",
       "      <td>218568.0</td>\n",
       "      <td>2017-07-06 23:30</td>\n",
       "      <td>165101.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389161</th>\n",
       "      <td>258090.0</td>\n",
       "      <td>2017-07-02 16:35</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>I</td>\n",
       "      <td>396664.0</td>\n",
       "      <td>51181.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389162</th>\n",
       "      <td>346235.0</td>\n",
       "      <td>2017-07-03 20:57</td>\n",
       "      <td>744441.0</td>\n",
       "      <td>H</td>\n",
       "      <td>414149.0</td>\n",
       "      <td>45962.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389163 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id          DateTime    user_id product  campaign_id  \\\n",
       "0          98528.0  2017-07-04 16:42     7716.0       C     405490.0   \n",
       "1         589714.0  2017-07-07 07:40  1035283.0       I     118601.0   \n",
       "2         478652.0  2017-07-07 20:42    65994.0       H     359520.0   \n",
       "3          34536.0  2017-07-05 15:05    75976.0       H     405490.0   \n",
       "4          71863.0  2017-07-06 20:11   987498.0       C     405490.0   \n",
       "...            ...               ...        ...     ...          ...   \n",
       "389158    464382.0  2017-07-02 08:03   927351.0       I     359520.0   \n",
       "389159    446419.0  2017-07-04 21:14   698480.0       H     360936.0   \n",
       "389160    218568.0  2017-07-06 23:30   165101.0       I     118601.0   \n",
       "389161    258090.0  2017-07-02 16:35     2179.0       I     396664.0   \n",
       "389162    346235.0  2017-07-03 20:57   744441.0       H     414149.0   \n",
       "\n",
       "        webpage_id  product_category_1  product_category_2  user_group_id  \\\n",
       "0          60305.0                 3.0                 NaN            3.0   \n",
       "1          28529.0                 4.0             82527.0           10.0   \n",
       "2          13787.0                 4.0                 NaN            4.0   \n",
       "3          60305.0                 3.0                 NaN            3.0   \n",
       "4          60305.0                 3.0                 NaN            2.0   \n",
       "...            ...                 ...                 ...            ...   \n",
       "389158     13787.0                 3.0                 NaN            2.0   \n",
       "389159     13787.0                 3.0                 NaN            3.0   \n",
       "389160     28529.0                 4.0             82527.0            2.0   \n",
       "389161     51181.0                 1.0                 NaN            2.0   \n",
       "389162     45962.0                 5.0                 NaN            3.0   \n",
       "\n",
       "        gender  age_level  user_depth  city_development_index  var_1  is_click  \n",
       "0         Male        3.0         3.0                     NaN    1.0       1.0  \n",
       "1       Female        4.0         3.0                     3.0    1.0       0.0  \n",
       "2         Male        4.0         3.0                     2.0    0.0       0.0  \n",
       "3         Male        3.0         3.0                     3.0    0.0       0.0  \n",
       "4         Male        2.0         3.0                     2.0    0.0       0.0  \n",
       "...        ...        ...         ...                     ...    ...       ...  \n",
       "389158    Male        2.0         3.0                     NaN    1.0       0.0  \n",
       "389159    Male        3.0         3.0                     1.0    1.0       0.0  \n",
       "389160    Male        2.0         3.0                     NaN    1.0       0.0  \n",
       "389161    Male        2.0         3.0                     4.0    0.0       0.0  \n",
       "389162    Male        3.0         3.0                     4.0    0.0       1.0  \n",
       "\n",
       "[389163 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `clean_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where both session_id and DateTime are missing\n",
    "clean_df = ctr_df.dropna(subset=['session_id', 'DateTime'], how='all')\n",
    "\n",
    "# Remove duplicates\n",
    "clean_df = clean_df.drop_duplicates()\n",
    "\n",
    "# Some columns have very few missing values (less than 100), while others have many missing values.\n",
    "# We only want to remove rows that have missing values in the columns where missing data is rare,\n",
    "# as these might be errors in data collection\n",
    "low_missing_columns = [\n",
    "    'session_id', 'DateTime', 'user_id', 'product', \n",
    "    'campaign_id', 'webpage_id', 'product_category_1', 'var_1', 'is_click'\n",
    "]\n",
    "clean_df = clean_df.dropna(subset=low_missing_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98528.0</td>\n",
       "      <td>2017-07-04 16:42</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589714.0</td>\n",
       "      <td>2017-07-07 07:40</td>\n",
       "      <td>1035283.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478652.0</td>\n",
       "      <td>2017-07-07 20:42</td>\n",
       "      <td>65994.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34536.0</td>\n",
       "      <td>2017-07-05 15:05</td>\n",
       "      <td>75976.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71863.0</td>\n",
       "      <td>2017-07-06 20:11</td>\n",
       "      <td>987498.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370627</th>\n",
       "      <td>255315.0</td>\n",
       "      <td>2017-07-05 11:16</td>\n",
       "      <td>649732.0</td>\n",
       "      <td>I</td>\n",
       "      <td>396664.0</td>\n",
       "      <td>51181.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370628</th>\n",
       "      <td>198717.0</td>\n",
       "      <td>2017-07-06 16:32</td>\n",
       "      <td>449081.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370629</th>\n",
       "      <td>46593.0</td>\n",
       "      <td>2017-07-03 15:58</td>\n",
       "      <td>382258.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370630</th>\n",
       "      <td>317516.0</td>\n",
       "      <td>2017-07-03 19:34</td>\n",
       "      <td>367796.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370631</th>\n",
       "      <td>15927.0</td>\n",
       "      <td>2017-07-03 13:33</td>\n",
       "      <td>1129457.0</td>\n",
       "      <td>F</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363537 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id          DateTime    user_id product  campaign_id  \\\n",
       "0          98528.0  2017-07-04 16:42     7716.0       C     405490.0   \n",
       "1         589714.0  2017-07-07 07:40  1035283.0       I     118601.0   \n",
       "2         478652.0  2017-07-07 20:42    65994.0       H     359520.0   \n",
       "3          34536.0  2017-07-05 15:05    75976.0       H     405490.0   \n",
       "4          71863.0  2017-07-06 20:11   987498.0       C     405490.0   \n",
       "...            ...               ...        ...     ...          ...   \n",
       "370627    255315.0  2017-07-05 11:16   649732.0       I     396664.0   \n",
       "370628    198717.0  2017-07-06 16:32   449081.0       I     118601.0   \n",
       "370629     46593.0  2017-07-03 15:58   382258.0       C     405490.0   \n",
       "370630    317516.0  2017-07-03 19:34   367796.0       H     359520.0   \n",
       "370631     15927.0  2017-07-03 13:33  1129457.0       F     405490.0   \n",
       "\n",
       "        webpage_id  product_category_1  product_category_2  user_group_id  \\\n",
       "0          60305.0                 3.0                 NaN            3.0   \n",
       "1          28529.0                 4.0             82527.0           10.0   \n",
       "2          13787.0                 4.0                 NaN            4.0   \n",
       "3          60305.0                 3.0                 NaN            3.0   \n",
       "4          60305.0                 3.0                 NaN            2.0   \n",
       "...            ...                 ...                 ...            ...   \n",
       "370627     51181.0                 1.0                 NaN            5.0   \n",
       "370628     28529.0                 4.0             82527.0            2.0   \n",
       "370629     60305.0                 3.0                 NaN            2.0   \n",
       "370630     13787.0                 4.0                 NaN            3.0   \n",
       "370631     60305.0                 3.0                 NaN            3.0   \n",
       "\n",
       "        gender  age_level  user_depth  city_development_index  var_1  is_click  \n",
       "0         Male        3.0         3.0                     NaN    1.0       1.0  \n",
       "1       Female        4.0         3.0                     3.0    1.0       0.0  \n",
       "2         Male        4.0         3.0                     2.0    0.0       0.0  \n",
       "3         Male        3.0         3.0                     3.0    0.0       0.0  \n",
       "4         Male        2.0         3.0                     2.0    0.0       0.0  \n",
       "...        ...        ...         ...                     ...    ...       ...  \n",
       "370627    Male        5.0         2.0                     NaN    0.0       0.0  \n",
       "370628    Male        2.0         3.0                     3.0    0.0       0.0  \n",
       "370629    Male        2.0         3.0                     NaN    1.0       0.0  \n",
       "370630    Male        3.0         3.0                     1.0    1.0       0.0  \n",
       "370631    Male        3.0         3.0                     3.0    0.0       0.0  \n",
       "\n",
       "[363537 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_features(df):\n",
    "    \n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Convert DateTime column to datetime type and extract hour\n",
    "    processed_df['DateTime'] = pd.to_datetime(processed_df['DateTime'])\n",
    "    # Create cyclical hour features\n",
    "    processed_df['hour_sin'] = np.sin(2 * np.pi * processed_df['DateTime'].dt.hour/24)\n",
    "    processed_df['hour_cos'] = np.cos(2 * np.pi * processed_df['DateTime'].dt.hour/24)\n",
    "    # Remove DateTime column since we've extracted the hour features\n",
    "    processed_df = processed_df.drop('DateTime', axis=1)\n",
    "\n",
    "    # One-hot encode the product column\n",
    "    product_dummies = pd.get_dummies(processed_df['product'], prefix='product')\n",
    "    # Add the one-hot encoded columns to the dataframe\n",
    "    processed_df = pd.concat([processed_df, product_dummies], axis=1)\n",
    "    # Drop the original product column\n",
    "    processed_df = processed_df.drop('product', axis=1)\n",
    "\n",
    "    # One-hot encode the gender column\n",
    "    gender_dummies = pd.get_dummies(processed_df['gender'], prefix='gender')\n",
    "    # Add the one-hot encoded columns to the dataframe\n",
    "    processed_df = pd.concat([processed_df, gender_dummies], axis=1)\n",
    "    # Drop the original gender column\n",
    "    processed_df = processed_df.drop('gender', axis=1)\n",
    "\n",
    "    # Drop session_id and user_id as they don't provide meaningful information for prediction\n",
    "    processed_df = processed_df.drop(['session_id', 'user_id'], axis=1)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "# Apply preprocessing to clean_df\n",
    "clean_df = preprocess_features(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "      <th>...</th>\n",
       "      <th>product_C</th>\n",
       "      <th>product_D</th>\n",
       "      <th>product_E</th>\n",
       "      <th>product_F</th>\n",
       "      <th>product_G</th>\n",
       "      <th>product_H</th>\n",
       "      <th>product_I</th>\n",
       "      <th>product_J</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370627</th>\n",
       "      <td>396664.0</td>\n",
       "      <td>51181.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370628</th>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370629</th>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370630</th>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370631</th>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363537 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        campaign_id  webpage_id  product_category_1  product_category_2  \\\n",
       "0          405490.0     60305.0                 3.0                 NaN   \n",
       "1          118601.0     28529.0                 4.0             82527.0   \n",
       "2          359520.0     13787.0                 4.0                 NaN   \n",
       "3          405490.0     60305.0                 3.0                 NaN   \n",
       "4          405490.0     60305.0                 3.0                 NaN   \n",
       "...             ...         ...                 ...                 ...   \n",
       "370627     396664.0     51181.0                 1.0                 NaN   \n",
       "370628     118601.0     28529.0                 4.0             82527.0   \n",
       "370629     405490.0     60305.0                 3.0                 NaN   \n",
       "370630     359520.0     13787.0                 4.0                 NaN   \n",
       "370631     405490.0     60305.0                 3.0                 NaN   \n",
       "\n",
       "        user_group_id  age_level  user_depth  city_development_index  var_1  \\\n",
       "0                 3.0        3.0         3.0                     NaN    1.0   \n",
       "1                10.0        4.0         3.0                     3.0    1.0   \n",
       "2                 4.0        4.0         3.0                     2.0    0.0   \n",
       "3                 3.0        3.0         3.0                     3.0    0.0   \n",
       "4                 2.0        2.0         3.0                     2.0    0.0   \n",
       "...               ...        ...         ...                     ...    ...   \n",
       "370627            5.0        5.0         2.0                     NaN    0.0   \n",
       "370628            2.0        2.0         3.0                     3.0    0.0   \n",
       "370629            2.0        2.0         3.0                     NaN    1.0   \n",
       "370630            3.0        3.0         3.0                     1.0    1.0   \n",
       "370631            3.0        3.0         3.0                     3.0    0.0   \n",
       "\n",
       "        is_click  ...  product_C  product_D  product_E  product_F  product_G  \\\n",
       "0            1.0  ...       True      False      False      False      False   \n",
       "1            0.0  ...      False      False      False      False      False   \n",
       "2            0.0  ...      False      False      False      False      False   \n",
       "3            0.0  ...      False      False      False      False      False   \n",
       "4            0.0  ...       True      False      False      False      False   \n",
       "...          ...  ...        ...        ...        ...        ...        ...   \n",
       "370627       0.0  ...      False      False      False      False      False   \n",
       "370628       0.0  ...      False      False      False      False      False   \n",
       "370629       0.0  ...       True      False      False      False      False   \n",
       "370630       0.0  ...      False      False      False      False      False   \n",
       "370631       0.0  ...      False      False      False       True      False   \n",
       "\n",
       "        product_H  product_I  product_J  gender_Female  gender_Male  \n",
       "0           False      False      False          False         True  \n",
       "1           False       True      False           True        False  \n",
       "2            True      False      False          False         True  \n",
       "3            True      False      False          False         True  \n",
       "4           False      False      False          False         True  \n",
       "...           ...        ...        ...            ...          ...  \n",
       "370627      False       True      False          False         True  \n",
       "370628      False       True      False          False         True  \n",
       "370629      False      False      False          False         True  \n",
       "370630       True      False      False          False         True  \n",
       "370631      False      False      False          False         True  \n",
       "\n",
       "[363537 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_is_click = clean_df[clean_df['is_click'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_not_click = clean_df[clean_df['is_click'] == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clicks (original): 24598\n",
      "Number of non-clicks (original): 338939\n",
      "\n",
      "Created 2 \"balanced\" datasets:\n",
      "- Clicks: 24598\n",
      "- Non-clicks sampled: 24598\n",
      "- Total samples per dataset: 49196\n",
      "- Ratio of non-clicks to clicks: 1:1\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_datasets(only_is_click, only_not_click, num_balanced_datasets=5, ratio_of_not_click_samples=2):\n",
    "    \"\"\"\n",
    "    Create multiple balanced datasets by sampling from non-clicks.\n",
    "    \n",
    "    Args:\n",
    "        only_is_click (pd.DataFrame): DataFrame containing only click data\n",
    "        only_not_click (pd.DataFrame): DataFrame containing only non-click data\n",
    "        n_iterations (int): Number of balanced datasets to create\n",
    "        \n",
    "    Returns:\n",
    "        list: List of balanced DataFrames\n",
    "    \"\"\"\n",
    "    balanced_datasets = []\n",
    "    n_not_click_samples = len(only_is_click) * ratio_of_not_click_samples\n",
    "\n",
    "    for i in range(num_balanced_datasets):\n",
    "        # Sample from non-clicks with replacement\n",
    "        sampled_not_click = only_not_click.sample(n=n_not_click_samples, random_state=i)\n",
    "        \n",
    "        # Combine with clicks\n",
    "        balanced = pd.concat([only_is_click, sampled_not_click], ignore_index=True)\n",
    "        \n",
    "        # Shuffle the dataset\n",
    "        balanced = balanced.sample(frac=1, random_state=i).reset_index(drop=True)\n",
    "        \n",
    "        balanced_datasets.append(balanced)\n",
    "\n",
    "    # Print information about the balanced datasets\n",
    "    print(f\"Number of clicks (original): {len(only_is_click)}\")\n",
    "    print(f\"Number of non-clicks (original): {len(only_not_click)}\")\n",
    "    print(f\"\\nCreated {num_balanced_datasets} \\\"balanced\\\" datasets:\")\n",
    "    print(f\"- Clicks: {len(only_is_click)}\")\n",
    "    print(f\"- Non-clicks sampled: {n_not_click_samples}\")\n",
    "    print(f\"- Total samples per dataset: {len(only_is_click) + n_not_click_samples}\")\n",
    "    print(f\"- Ratio of non-clicks to clicks: {ratio_of_not_click_samples}:1\")\n",
    "        \n",
    "    return balanced_datasets\n",
    "\n",
    "# Create multiple balanced datasets\n",
    "balanced_datasets = create_balanced_datasets(only_is_click, only_not_click, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/2\n",
      "Cross validation F1 scores: 0.551 (+/- 0.005)\n",
      "Cross validation AUC scores: 0.563 (+/- 0.001)\n",
      "Training model 2/2\n",
      "Cross validation F1 scores: 0.552 (+/- 0.007)\n",
      "Cross validation AUC scores: 0.564 (+/- 0.005)\n",
      "\n",
      "Ensemble Model Performance:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.56      0.71     67753\n",
      "         1.0       0.11      0.73      0.19      4955\n",
      "\n",
      "    accuracy                           0.58     72708\n",
      "   macro avg       0.54      0.65      0.45     72708\n",
      "weighted avg       0.91      0.58      0.68     72708\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.7050566041490144\n",
      "\n",
      "F1 Score: 0.18937304651590367\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38240 29513]\n",
      " [ 1350  3605]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Create a common test set from the original clean_df\n",
    "X = clean_df.drop('is_click', axis=1)\n",
    "y = clean_df['is_click']\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = []\n",
    "predictions_prob = []\n",
    "\n",
    "for i, balanced_df in enumerate(balanced_datasets):\n",
    "    print(f\"Training model {i+1}/{len(balanced_datasets)}\")\n",
    "    \n",
    "    y_bal = balanced_df['is_click']\n",
    "    X_bal = balanced_df.drop('is_click', axis=1)\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_bal):\n",
    "        X_train, X_val = X_bal.iloc[train_idx], X_bal.iloc[val_idx]\n",
    "        y_train, y_val = y_bal.iloc[train_idx], y_bal.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "        auc_scores.append(roc_auc_score(y_val, y_pred_prob))\n",
    "    \n",
    "    print(f\"Cross validation F1 scores: {np.mean(f1_scores):.3f} (+/- {np.std(f1_scores):.3f})\")\n",
    "    print(f\"Cross validation AUC scores: {np.mean(auc_scores):.3f} (+/- {np.std(auc_scores):.3f})\")\n",
    "    \n",
    "    # Fit on full balanced dataset\n",
    "    model.fit(X_bal, y_bal)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    predictions_prob.append(y_pred_prob)\n",
    "    models.append(model)\n",
    "\n",
    "# Combine predictions by averaging probabilities\n",
    "final_predictions_prob = np.mean(predictions_prob, axis=0)\n",
    "final_predictions = (final_predictions_prob >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print(\"\\nEnsemble Model Performance:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_predictions))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test, final_predictions_prob))\n",
    "print(\"\\nF1 Score:\", f1_score(y_test, final_predictions))\n",
    "\n",
    "# Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "final_ensemble = {\n",
    "    'models': models,\n",
    "    'feature_columns': X.columns,\n",
    "    'threshold': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/2\n",
      "Best params for dataset 1: {'max_depth': 10, 'min_child_weight': 5, 'gamma': 0.1, 'subsample': 1.0, 'colsample_bytree': 0.6, 'learning_rate': 0.05, 'n_estimators': 50, 'reg_alpha': 0.1, 'reg_lambda': 2}\n",
      "Best CV F1 score for dataset 1: 0.552\n",
      "Training model 2/2\n",
      "Best params for dataset 2: {'max_depth': 7, 'min_child_weight': 5, 'gamma': 0, 'subsample': 0.6, 'colsample_bytree': 0.8, 'learning_rate': 0.1, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 2}\n",
      "Best CV F1 score for dataset 2: 0.549\n",
      "\n",
      "Ensemble Model Performance:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.58      0.72     67753\n",
      "         1.0       0.10      0.63      0.17      4955\n",
      "\n",
      "    accuracy                           0.58     72708\n",
      "   macro avg       0.53      0.61      0.45     72708\n",
      "weighted avg       0.90      0.58      0.68     72708\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.6469060861138585\n",
      "\n",
      "F1 Score: 0.17113497854663715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39248 28505]\n",
      " [ 1824  3131]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "X = clean_df.drop('is_click', axis=1)\n",
    "y = clean_df['is_click']\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = []\n",
    "predictions_prob = []\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "n_iter = 20  # number of random combinations\n",
    "\n",
    "for i, balanced_df in enumerate(balanced_datasets):\n",
    "    print(f\"Training model {i+1}/{len(balanced_datasets)}\")\n",
    "    \n",
    "    y_bal = balanced_df['is_click']\n",
    "    X_bal = balanced_df.drop('is_click', axis=1)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_params = None\n",
    "    best_f1 = -np.inf\n",
    "    \n",
    "    # Manual random search\n",
    "    for _ in range(n_iter):\n",
    "        params = {key: random.choice(values) for key, values in param_dist.items()}\n",
    "        f1_scores = []\n",
    "        for train_idx, val_idx in kf.split(X_bal):\n",
    "            X_train, X_val = X_bal.iloc[train_idx], X_bal.iloc[val_idx]\n",
    "            y_train, y_val = y_bal.iloc[train_idx], y_bal.iloc[val_idx]\n",
    "            \n",
    "            model = XGBClassifier(**params, eval_metric='logloss', random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            f1_scores.append(f1_score(y_val, y_pred))\n",
    "        avg_f1 = np.mean(f1_scores)\n",
    "        if avg_f1 > best_f1:\n",
    "            best_f1 = avg_f1\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best params for dataset {i+1}: {best_params}\")\n",
    "    print(f\"Best CV F1 score for dataset {i+1}: {best_f1:.3f}\")\n",
    "    \n",
    "    # Train final model on full balanced dataset with best parameters\n",
    "    best_model = XGBClassifier(**best_params, eval_metric='logloss', random_state=42)\n",
    "    best_model.fit(X_bal, y_bal)\n",
    "    y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    predictions_prob.append(y_pred_prob)\n",
    "    models.append(best_model)\n",
    "\n",
    "# Ensemble predictions by averaging\n",
    "final_predictions_prob = np.mean(predictions_prob, axis=0)\n",
    "final_predictions = (final_predictions_prob >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\nEnsemble Model Performance:\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_predictions))\n",
    "print(\"\\nROC AUC Score:\", roc_auc_score(y_test, final_predictions_prob))\n",
    "print(\"\\nF1 Score:\", f1_score(y_test, final_predictions))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, final_predictions))\n",
    "\n",
    "final_ensemble = {\n",
    "    'models': models,\n",
    "    'feature_columns': X.columns,\n",
    "    'threshold': 0.5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import numpy as np\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import train_test_split, KFold\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Disable Optuna logs\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# # Train/test split\n",
    "# X = clean_df.drop('is_click', axis=1)\n",
    "# y = clean_df['is_click']\n",
    "# _, X_test, _, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Select first balanced dataset for hyperparameter tuning\n",
    "# balanced_df = balanced_datasets[0]\n",
    "# y_bal = balanced_df['is_click']\n",
    "# X_bal = balanced_df.drop('is_click', axis=1)\n",
    "\n",
    "# # Optuna objective function\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "#         'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.1),\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1.0, 2.0),\n",
    "#         'eval_metric': 'logloss',\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "    \n",
    "#     kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     f1_scores = []\n",
    "\n",
    "#     for train_idx, val_idx in kf.split(X_bal):\n",
    "#         X_train, X_val = X_bal.iloc[train_idx], X_bal.iloc[val_idx]\n",
    "#         y_train, y_val = y_bal.iloc[train_idx], y_bal.iloc[val_idx]\n",
    "\n",
    "#         model = XGBClassifier(**params)\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_val)\n",
    "#         f1_scores.append(f1_score(y_val, y_pred))\n",
    "\n",
    "#     return np.mean(f1_scores)\n",
    "\n",
    "# # Run Optuna optimization\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=20)\n",
    "\n",
    "# # Best parameters found\n",
    "# best_params = study.best_params\n",
    "# print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# # Train models on all balanced datasets with best params\n",
    "# models = []\n",
    "# predictions_prob = []\n",
    "\n",
    "# for i, balanced_df in enumerate(balanced_datasets):\n",
    "#     print(f\"Training model {i+1}/{len(balanced_datasets)}\")\n",
    "    \n",
    "#     y_bal = balanced_df['is_click']\n",
    "#     X_bal = balanced_df.drop('is_click', axis=1)\n",
    "\n",
    "#     best_model = XGBClassifier(**best_params, eval_metric='logloss', random_state=42)\n",
    "#     best_model.fit(X_bal, y_bal)\n",
    "    \n",
    "#     y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "#     predictions_prob.append(y_pred_prob)\n",
    "#     models.append(best_model)\n",
    "\n",
    "# # Ensemble predictions\n",
    "# final_predictions_prob = np.mean(predictions_prob, axis=0)\n",
    "# threshold = 0.55\n",
    "# final_predictions = (final_predictions_prob >= threshold).astype(int)\n",
    "\n",
    "# # Evaluate model\n",
    "# from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# print(\"\\nEnsemble Model Performance:\")\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, final_predictions))\n",
    "# print(\"\\nROC AUC Score:\", roc_auc_score(y_test, final_predictions_prob))\n",
    "# print(\"\\nF1 Score:\", f1_score(y_test, final_predictions))\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, final_predictions))\n",
    "\n",
    "# final_ensemble = {\n",
    "#     'models': models,\n",
    "#     'feature_columns': X.columns,\n",
    "#     'threshold': threshold\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_ensemble(X_new, ensemble):\n",
    "    \n",
    "    # Ensure X_new has the same columns as training data\n",
    "    X_new = X_new[ensemble['feature_columns']]\n",
    "    \n",
    "    # Get predictions from all models\n",
    "    predictions_prob = np.mean([\n",
    "        model.predict_proba(X_new)[:, 1] \n",
    "        for model in ensemble['models']\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Convert to binary predictions\n",
    "    predictions = (predictions_prob >= ensemble['threshold']).astype(int)\n",
    "    \n",
    "    return predictions, predictions_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model evaluation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(X, y):\n",
    "    \n",
    "    test_df_processed = preprocess_features(X)  \n",
    "\n",
    "    test_predictions, test_predictions_prob = predict_with_ensemble(test_df_processed, final_ensemble)\n",
    "\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y, test_predictions))\n",
    "    print(\"\\nF1 Score:\", f1_score(y, test_predictions))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y, test_predictions)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    return test_predictions, test_predictions_prob, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.58      0.72    359012\n",
      "         1.0       0.10      0.63      0.17     26019\n",
      "\n",
      "    accuracy                           0.58    385031\n",
      "   macro avg       0.53      0.60      0.44    385031\n",
      "weighted avg       0.90      0.58      0.68    385031\n",
      "\n",
      "\n",
      "F1 Score: 0.1690438620917257\n",
      "\n",
      "Confusion Matrix:\n",
      "[[207496 151516]\n",
      " [  9628  16391]]\n"
     ]
    }
   ],
   "source": [
    "test_X = pd.read_csv('../data/train_dataset_full.csv')\n",
    "test_X = test_X.dropna(subset=['is_click'])\n",
    "test_y = test_X['is_click']\n",
    "\n",
    "test_predictions, test_predictions_prob, y_true = evaluate_model_performance(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 1], shape=(385031,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Performance:\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.59      0.73     56152\n",
      "           1       0.09      0.53      0.15      4075\n",
      "\n",
      "    accuracy                           0.59     60227\n",
      "   macro avg       0.52      0.56      0.44     60227\n",
      "weighted avg       0.89      0.59      0.69     60227\n",
      "\n",
      "\n",
      "F1 Score: 0.14712328767123287\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33175 22977]\n",
      " [ 1927  2148]]\n"
     ]
    }
   ],
   "source": [
    "test_X = pd.read_csv('../data/X_test_1st.csv')\n",
    "test_X = test_X.iloc[1:]\n",
    "\n",
    "test_y = pd.read_csv('../data/y_test_1st.csv')\n",
    "\n",
    "test_predictions, test_predictions_prob, y_true = evaluate_model_performance(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess test data using the same feature engineering as training data\n",
    "# test_df_encoded = pd.get_dummies(test_df, columns=['product', 'gender'])\n",
    "\n",
    "# # Ensure test data has same columns as training data\n",
    "# missing_cols = set(X.columns) - set(test_df_encoded.columns)\n",
    "# for col in missing_cols:\n",
    "#     test_df_encoded[col] = 0\n",
    "# test_df_encoded = test_df_encoded[X.columns]\n",
    "\n",
    "# # Make predictions using the ensemble model\n",
    "# test_predictions_prob = np.mean([model.predict_proba(test_df_encoded)[:, 1] for model in models], axis=0)\n",
    "# test_predictions = (test_predictions_prob >= 0.5).astype(int)\n",
    "\n",
    "# # Create submission dataframe\n",
    "# submission = pd.DataFrame({\n",
    "#     'id': range(len(test_predictions)),\n",
    "#     'click': test_predictions\n",
    "# })\n",
    "\n",
    "# # Save predictions\n",
    "# submission.to_csv('../data/predictions.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform architecture: ('64bit', '')\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f\"Platform architecture: {platform.architecture()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
